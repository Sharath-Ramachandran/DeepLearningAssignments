{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingModel(dataLoader):\n",
    "    for epoch in range(10):\n",
    "        ave_loss=0.0\n",
    "        print(\"Epoch \",epoch+1)\n",
    "        for i,data in enumerate(dataLoader,0):\n",
    "            inputs,target =data\n",
    "            #inputs = inputs.float()\n",
    "            target = target.float()\n",
    "            optimizer.zero_grad()\n",
    "            output=model(inputs)\n",
    "            #output = output.long()\n",
    "            target = target.unsqueeze(1)\n",
    "            loss=criteria(output,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ave_loss+=loss.item()\n",
    "        print(\"Loss for Epoch \",epoch+1,\" is \",(ave_loss/x_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the dataframe to numpy array to tensor array\n",
    "def changeToTensor(dataFrame):\n",
    "    dataFrame= (dataFrame-dataFrame.min())/(dataFrame.max()-dataFrame.min())\n",
    "    x = dataFrame.values\n",
    "    x= x.astype('float64')\n",
    "    x= torch.Tensor(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.txt',sep=',')\n",
    "test_data = pd.read_csv('test.txt',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-04 17:51:00</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2015-02-04 17:51:59</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-04 17:53:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2015-02-04 17:54:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2015-02-04 17:55:00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Temperature  Humidity  Light     CO2  HumidityRatio  \\\n",
       "1  2015-02-04 17:51:00        23.18   27.2720  426.0  721.25       0.004793   \n",
       "2  2015-02-04 17:51:59        23.15   27.2675  429.5  714.00       0.004783   \n",
       "3  2015-02-04 17:53:00        23.15   27.2450  426.0  713.50       0.004779   \n",
       "4  2015-02-04 17:54:00        23.15   27.2000  426.0  708.25       0.004772   \n",
       "5  2015-02-04 17:55:00        23.10   27.2000  426.0  704.50       0.004757   \n",
       "\n",
       "   Occupancy  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a model with pytorch#####\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(size,2000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(2000,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numpy = train_data.values\n",
    "labels = train_numpy[:,-1]\n",
    "labels= labels.astype('float64')\n",
    "labels= torch.Tensor(labels)\n",
    "train_sub = train_data.drop(['date','Occupancy'],axis=1)\n",
    "x_train = changeToTensor(train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8143, 5]), torch.Size([8143, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=5, out_features=2000, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=2000, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria= nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, criterion, batch_size=50):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, x_train.size(0), batch_size):\n",
    "        x_batch = x_train[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = labels[beg_i:beg_i + batch_size, :]\n",
    "#         x_batch = Variable(x_batch)\n",
    "#         y_batch = Variable(y_batch)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_batch)\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch  1 loss is  [array(0.72885686, dtype=float32)]\n",
      "For epoch  2 loss is  [array(0.6558166, dtype=float32)]\n",
      "For epoch  3 loss is  [array(0.60309345, dtype=float32)]\n",
      "For epoch  4 loss is  [array(0.5678936, dtype=float32)]\n",
      "For epoch  5 loss is  [array(0.54588014, dtype=float32)]\n",
      "For epoch  6 loss is  [array(0.5321321, dtype=float32)]\n",
      "For epoch  7 loss is  [array(0.52231324, dtype=float32)]\n",
      "For epoch  8 loss is  [array(0.51332825, dtype=float32)]\n",
      "For epoch  9 loss is  [array(0.5033764, dtype=float32)]\n",
      "For epoch  10 loss is  [array(0.49167514, dtype=float32)]\n",
      "For epoch  11 loss is  [array(0.47814584, dtype=float32)]\n",
      "For epoch  12 loss is  [array(0.46313557, dtype=float32)]\n",
      "For epoch  13 loss is  [array(0.4472326, dtype=float32)]\n",
      "For epoch  14 loss is  [array(0.43111473, dtype=float32)]\n",
      "For epoch  15 loss is  [array(0.41545853, dtype=float32)]\n",
      "For epoch  16 loss is  [array(0.40082586, dtype=float32)]\n",
      "For epoch  17 loss is  [array(0.38759664, dtype=float32)]\n",
      "For epoch  18 loss is  [array(0.37591478, dtype=float32)]\n",
      "For epoch  19 loss is  [array(0.36567566, dtype=float32)]\n",
      "For epoch  20 loss is  [array(0.35656604, dtype=float32)]\n",
      "For epoch  21 loss is  [array(0.34816158, dtype=float32)]\n",
      "For epoch  22 loss is  [array(0.34003296, dtype=float32)]\n",
      "For epoch  23 loss is  [array(0.33185264, dtype=float32)]\n",
      "For epoch  24 loss is  [array(0.323442, dtype=float32)]\n",
      "For epoch  25 loss is  [array(0.31478858, dtype=float32)]\n",
      "For epoch  26 loss is  [array(0.30600378, dtype=float32)]\n",
      "For epoch  27 loss is  [array(0.29727402, dtype=float32)]\n",
      "For epoch  28 loss is  [array(0.28879806, dtype=float32)]\n",
      "For epoch  29 loss is  [array(0.2807389, dtype=float32)]\n",
      "For epoch  30 loss is  [array(0.2731939, dtype=float32)]\n",
      "For epoch  31 loss is  [array(0.26618958, dtype=float32)]\n",
      "For epoch  32 loss is  [array(0.25968665, dtype=float32)]\n",
      "For epoch  33 loss is  [array(0.25359896, dtype=float32)]\n",
      "For epoch  34 loss is  [array(0.24782577, dtype=float32)]\n",
      "For epoch  35 loss is  [array(0.24227266, dtype=float32)]\n",
      "For epoch  36 loss is  [array(0.23686633, dtype=float32)]\n",
      "For epoch  37 loss is  [array(0.23156488, dtype=float32)]\n",
      "For epoch  38 loss is  [array(0.22636001, dtype=float32)]\n",
      "For epoch  39 loss is  [array(0.22127211, dtype=float32)]\n",
      "For epoch  40 loss is  [array(0.21633361, dtype=float32)]\n",
      "For epoch  41 loss is  [array(0.21157868, dtype=float32)]\n",
      "For epoch  42 loss is  [array(0.20703566, dtype=float32)]\n",
      "For epoch  43 loss is  [array(0.20271999, dtype=float32)]\n",
      "For epoch  44 loss is  [array(0.19862816, dtype=float32)]\n",
      "For epoch  45 loss is  [array(0.19474466, dtype=float32)]\n",
      "For epoch  46 loss is  [array(0.19104275, dtype=float32)]\n",
      "For epoch  47 loss is  [array(0.18748894, dtype=float32)]\n",
      "For epoch  48 loss is  [array(0.18405414, dtype=float32)]\n",
      "For epoch  49 loss is  [array(0.1807159, dtype=float32)]\n",
      "For epoch  50 loss is  [array(0.17746308, dtype=float32)]\n",
      "For epoch  51 loss is  [array(0.17429, dtype=float32)]\n",
      "For epoch  52 loss is  [array(0.17119753, dtype=float32)]\n",
      "For epoch  53 loss is  [array(0.16819164, dtype=float32)]\n",
      "For epoch  54 loss is  [array(0.1652788, dtype=float32)]\n",
      "For epoch  55 loss is  [array(0.1624642, dtype=float32)]\n",
      "For epoch  56 loss is  [array(0.1597515, dtype=float32)]\n",
      "For epoch  57 loss is  [array(0.15713729, dtype=float32)]\n",
      "For epoch  58 loss is  [array(0.1546144, dtype=float32)]\n",
      "For epoch  59 loss is  [array(0.15217613, dtype=float32)]\n",
      "For epoch  60 loss is  [array(0.14981353, dtype=float32)]\n",
      "For epoch  61 loss is  [array(0.14751635, dtype=float32)]\n",
      "For epoch  62 loss is  [array(0.14527519, dtype=float32)]\n",
      "For epoch  63 loss is  [array(0.14308661, dtype=float32)]\n",
      "For epoch  64 loss is  [array(0.14094637, dtype=float32)]\n",
      "For epoch  65 loss is  [array(0.13885482, dtype=float32)]\n",
      "For epoch  66 loss is  [array(0.13681385, dtype=float32)]\n",
      "For epoch  67 loss is  [array(0.13482293, dtype=float32)]\n",
      "For epoch  68 loss is  [array(0.13288154, dtype=float32)]\n",
      "For epoch  69 loss is  [array(0.1309873, dtype=float32)]\n",
      "For epoch  70 loss is  [array(0.12913963, dtype=float32)]\n",
      "For epoch  71 loss is  [array(0.12733555, dtype=float32)]\n",
      "For epoch  72 loss is  [array(0.12557295, dtype=float32)]\n",
      "For epoch  73 loss is  [array(0.12385055, dtype=float32)]\n",
      "For epoch  74 loss is  [array(0.12216798, dtype=float32)]\n",
      "For epoch  75 loss is  [array(0.1205231, dtype=float32)]\n",
      "For epoch  76 loss is  [array(0.11891311, dtype=float32)]\n",
      "For epoch  77 loss is  [array(0.11733714, dtype=float32)]\n",
      "For epoch  78 loss is  [array(0.11579444, dtype=float32)]\n",
      "For epoch  79 loss is  [array(0.1142842, dtype=float32)]\n",
      "For epoch  80 loss is  [array(0.11280621, dtype=float32)]\n",
      "For epoch  81 loss is  [array(0.11135929, dtype=float32)]\n",
      "For epoch  82 loss is  [array(0.1099456, dtype=float32)]\n",
      "For epoch  83 loss is  [array(0.10856263, dtype=float32)]\n",
      "For epoch  84 loss is  [array(0.10721093, dtype=float32)]\n",
      "For epoch  85 loss is  [array(0.10588907, dtype=float32)]\n",
      "For epoch  86 loss is  [array(0.1045953, dtype=float32)]\n",
      "For epoch  87 loss is  [array(0.10332965, dtype=float32)]\n",
      "For epoch  88 loss is  [array(0.10208973, dtype=float32)]\n",
      "For epoch  89 loss is  [array(0.10087562, dtype=float32)]\n",
      "For epoch  90 loss is  [array(0.09968657, dtype=float32)]\n",
      "For epoch  91 loss is  [array(0.09852286, dtype=float32)]\n",
      "For epoch  92 loss is  [array(0.09738392, dtype=float32)]\n",
      "For epoch  93 loss is  [array(0.09627002, dtype=float32)]\n",
      "For epoch  94 loss is  [array(0.09518034, dtype=float32)]\n",
      "For epoch  95 loss is  [array(0.09411632, dtype=float32)]\n",
      "For epoch  96 loss is  [array(0.09307581, dtype=float32)]\n",
      "For epoch  97 loss is  [array(0.09205781, dtype=float32)]\n",
      "For epoch  98 loss is  [array(0.09106193, dtype=float32)]\n",
      "For epoch  99 loss is  [array(0.09008915, dtype=float32)]\n",
      "For epoch  100 loss is  [array(0.08913822, dtype=float32)]\n",
      "For epoch  101 loss is  [array(0.08820809, dtype=float32)]\n",
      "For epoch  102 loss is  [array(0.08729801, dtype=float32)]\n",
      "For epoch  103 loss is  [array(0.08640724, dtype=float32)]\n",
      "For epoch  104 loss is  [array(0.085535, dtype=float32)]\n",
      "For epoch  105 loss is  [array(0.0846813, dtype=float32)]\n",
      "For epoch  106 loss is  [array(0.08384433, dtype=float32)]\n",
      "For epoch  107 loss is  [array(0.08302375, dtype=float32)]\n",
      "For epoch  108 loss is  [array(0.08221982, dtype=float32)]\n",
      "For epoch  109 loss is  [array(0.08143339, dtype=float32)]\n",
      "For epoch  110 loss is  [array(0.08066329, dtype=float32)]\n",
      "For epoch  111 loss is  [array(0.07991035, dtype=float32)]\n",
      "For epoch  112 loss is  [array(0.0791734, dtype=float32)]\n",
      "For epoch  113 loss is  [array(0.07845137, dtype=float32)]\n",
      "For epoch  114 loss is  [array(0.07774536, dtype=float32)]\n",
      "For epoch  115 loss is  [array(0.07705407, dtype=float32)]\n",
      "For epoch  116 loss is  [array(0.07637782, dtype=float32)]\n",
      "For epoch  117 loss is  [array(0.07571566, dtype=float32)]\n",
      "For epoch  118 loss is  [array(0.07506765, dtype=float32)]\n",
      "For epoch  119 loss is  [array(0.07443444, dtype=float32)]\n",
      "For epoch  120 loss is  [array(0.07381424, dtype=float32)]\n",
      "For epoch  121 loss is  [array(0.07320812, dtype=float32)]\n",
      "For epoch  122 loss is  [array(0.07261539, dtype=float32)]\n",
      "For epoch  123 loss is  [array(0.0720356, dtype=float32)]\n",
      "For epoch  124 loss is  [array(0.07146743, dtype=float32)]\n",
      "For epoch  125 loss is  [array(0.07091092, dtype=float32)]\n",
      "For epoch  126 loss is  [array(0.07036552, dtype=float32)]\n",
      "For epoch  127 loss is  [array(0.06983111, dtype=float32)]\n",
      "For epoch  128 loss is  [array(0.06930856, dtype=float32)]\n",
      "For epoch  129 loss is  [array(0.06879798, dtype=float32)]\n",
      "For epoch  130 loss is  [array(0.06829875, dtype=float32)]\n",
      "For epoch  131 loss is  [array(0.06781197, dtype=float32)]\n",
      "For epoch  132 loss is  [array(0.06733769, dtype=float32)]\n",
      "For epoch  133 loss is  [array(0.06687479, dtype=float32)]\n",
      "For epoch  134 loss is  [array(0.06642241, dtype=float32)]\n",
      "For epoch  135 loss is  [array(0.06597956, dtype=float32)]\n",
      "For epoch  136 loss is  [array(0.06554621, dtype=float32)]\n",
      "For epoch  137 loss is  [array(0.06512189, dtype=float32)]\n",
      "For epoch  138 loss is  [array(0.06470609, dtype=float32)]\n",
      "For epoch  139 loss is  [array(0.06429817, dtype=float32)]\n",
      "For epoch  140 loss is  [array(0.06389769, dtype=float32)]\n",
      "For epoch  141 loss is  [array(0.06350576, dtype=float32)]\n",
      "For epoch  142 loss is  [array(0.0631239, dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch  143 loss is  [array(0.06275105, dtype=float32)]\n",
      "For epoch  144 loss is  [array(0.06238598, dtype=float32)]\n",
      "For epoch  145 loss is  [array(0.06202828, dtype=float32)]\n",
      "For epoch  146 loss is  [array(0.06167765, dtype=float32)]\n",
      "For epoch  147 loss is  [array(0.06133426, dtype=float32)]\n",
      "For epoch  148 loss is  [array(0.06099817, dtype=float32)]\n",
      "For epoch  149 loss is  [array(0.06066954, dtype=float32)]\n",
      "For epoch  150 loss is  [array(0.06034875, dtype=float32)]\n",
      "For epoch  151 loss is  [array(0.06003475, dtype=float32)]\n",
      "For epoch  152 loss is  [array(0.05972778, dtype=float32)]\n",
      "For epoch  153 loss is  [array(0.05942732, dtype=float32)]\n",
      "For epoch  154 loss is  [array(0.05913348, dtype=float32)]\n",
      "For epoch  155 loss is  [array(0.0588458, dtype=float32)]\n",
      "For epoch  156 loss is  [array(0.05856417, dtype=float32)]\n",
      "For epoch  157 loss is  [array(0.0582878, dtype=float32)]\n",
      "For epoch  158 loss is  [array(0.05801702, dtype=float32)]\n",
      "For epoch  159 loss is  [array(0.05775212, dtype=float32)]\n",
      "For epoch  160 loss is  [array(0.05749276, dtype=float32)]\n",
      "For epoch  161 loss is  [array(0.05723942, dtype=float32)]\n",
      "For epoch  162 loss is  [array(0.05699117, dtype=float32)]\n",
      "For epoch  163 loss is  [array(0.05674785, dtype=float32)]\n",
      "For epoch  164 loss is  [array(0.05650861, dtype=float32)]\n",
      "For epoch  165 loss is  [array(0.05627386, dtype=float32)]\n",
      "For epoch  166 loss is  [array(0.05604303, dtype=float32)]\n",
      "For epoch  167 loss is  [array(0.05581628, dtype=float32)]\n",
      "For epoch  168 loss is  [array(0.05559422, dtype=float32)]\n",
      "For epoch  169 loss is  [array(0.05537646, dtype=float32)]\n",
      "For epoch  170 loss is  [array(0.0551628, dtype=float32)]\n",
      "For epoch  171 loss is  [array(0.05495355, dtype=float32)]\n",
      "For epoch  172 loss is  [array(0.0547478, dtype=float32)]\n",
      "For epoch  173 loss is  [array(0.05454583, dtype=float32)]\n",
      "For epoch  174 loss is  [array(0.05434701, dtype=float32)]\n",
      "For epoch  175 loss is  [array(0.05415148, dtype=float32)]\n",
      "For epoch  176 loss is  [array(0.05395942, dtype=float32)]\n",
      "For epoch  177 loss is  [array(0.05377097, dtype=float32)]\n",
      "For epoch  178 loss is  [array(0.05358547, dtype=float32)]\n",
      "For epoch  179 loss is  [array(0.0534032, dtype=float32)]\n",
      "For epoch  180 loss is  [array(0.05322402, dtype=float32)]\n",
      "For epoch  181 loss is  [array(0.05304758, dtype=float32)]\n",
      "For epoch  182 loss is  [array(0.05287394, dtype=float32)]\n",
      "For epoch  183 loss is  [array(0.05270288, dtype=float32)]\n",
      "For epoch  184 loss is  [array(0.05253506, dtype=float32)]\n",
      "For epoch  185 loss is  [array(0.05237038, dtype=float32)]\n",
      "For epoch  186 loss is  [array(0.05220848, dtype=float32)]\n",
      "For epoch  187 loss is  [array(0.05204963, dtype=float32)]\n",
      "For epoch  188 loss is  [array(0.05189323, dtype=float32)]\n",
      "For epoch  189 loss is  [array(0.05173976, dtype=float32)]\n",
      "For epoch  190 loss is  [array(0.05158887, dtype=float32)]\n",
      "For epoch  191 loss is  [array(0.05144026, dtype=float32)]\n",
      "For epoch  192 loss is  [array(0.05129391, dtype=float32)]\n",
      "For epoch  193 loss is  [array(0.05114984, dtype=float32)]\n",
      "For epoch  194 loss is  [array(0.05100762, dtype=float32)]\n",
      "For epoch  195 loss is  [array(0.05086764, dtype=float32)]\n",
      "For epoch  196 loss is  [array(0.05072955, dtype=float32)]\n",
      "For epoch  197 loss is  [array(0.05059378, dtype=float32)]\n",
      "For epoch  198 loss is  [array(0.05046024, dtype=float32)]\n",
      "For epoch  199 loss is  [array(0.05032838, dtype=float32)]\n",
      "For epoch  200 loss is  [array(0.0501986, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "for e in range(num_epochs):\n",
    "    e_losses = train_epoch(model,optimizer ,criteria,x_train.shape[0])\n",
    "    print(\"For epoch \",e+1,\"loss is \",e_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numpy = test_data.values\n",
    "output1 = test_numpy[:,-1]\n",
    "output1=output1.astype('float64')\n",
    "output1 = torch.Tensor(output1)\n",
    "test_sub = test_data.drop(['date','Occupancy'],axis=1)\n",
    "x_test = changeToTensor(test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9752, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test>0.5]=1\n",
    "test[test<=0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = test_numpy[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9752, 1), (9752,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-069d9247d360>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-069d9247d360>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    if(output1[i]==test[i])\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(test.shape[0]):\n",
    "    if(output1[i]==test[i]):\n",
    "        count = count+1\n",
    "print(\"Testing accuracy is \", (count/test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
