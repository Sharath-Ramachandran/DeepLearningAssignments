{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the dataframe to numpy array to tensor array\n",
    "def changeToTensor(dataFrame):\n",
    "    dataFrame= (dataFrame-dataFrame.min())/(dataFrame.max()-dataFrame.min())\n",
    "    x = dataFrame.values\n",
    "    x= x.astype('float64')\n",
    "    x= torch.Tensor(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.txt',sep=',')\n",
    "test_data = pd.read_csv('test.txt',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-04 17:51:00</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2015-02-04 17:51:59</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-04 17:53:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2015-02-04 17:54:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2015-02-04 17:55:00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Temperature  Humidity  Light     CO2  HumidityRatio  \\\n",
       "1  2015-02-04 17:51:00        23.18   27.2720  426.0  721.25       0.004793   \n",
       "2  2015-02-04 17:51:59        23.15   27.2675  429.5  714.00       0.004783   \n",
       "3  2015-02-04 17:53:00        23.15   27.2450  426.0  713.50       0.004779   \n",
       "4  2015-02-04 17:54:00        23.15   27.2000  426.0  708.25       0.004772   \n",
       "5  2015-02-04 17:55:00        23.10   27.2000  426.0  704.50       0.004757   \n",
       "\n",
       "   Occupancy  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a model with pytorch#####\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(size,100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numpy = train_data.values\n",
    "labels = train_numpy[:,-1]\n",
    "labels= labels.astype('float64')\n",
    "labels= torch.Tensor(labels)\n",
    "train_sub = train_data.drop(['date','Occupancy'],axis=1)\n",
    "x_train = changeToTensor(train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8143, 5]), torch.Size([8143, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=5, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria= nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, criterion, batch_size=50):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, x_train.size(0), batch_size):\n",
    "        #print(\"Came in for \",beg_i)\n",
    "        x_batch = x_train[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = labels[beg_i:beg_i + batch_size, :]\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_batch)\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch  1 loss is  [array(0.69088876, dtype=float32)]\n",
      "For epoch  2 loss is  [array(0.68590695, dtype=float32)]\n",
      "For epoch  3 loss is  [array(0.6810352, dtype=float32)]\n",
      "For epoch  4 loss is  [array(0.6762684, dtype=float32)]\n",
      "For epoch  5 loss is  [array(0.67160916, dtype=float32)]\n",
      "For epoch  6 loss is  [array(0.66706616, dtype=float32)]\n",
      "For epoch  7 loss is  [array(0.6626296, dtype=float32)]\n",
      "For epoch  8 loss is  [array(0.6583078, dtype=float32)]\n",
      "For epoch  9 loss is  [array(0.65409315, dtype=float32)]\n",
      "For epoch  10 loss is  [array(0.6499944, dtype=float32)]\n",
      "For epoch  11 loss is  [array(0.64600194, dtype=float32)]\n",
      "For epoch  12 loss is  [array(0.6421166, dtype=float32)]\n",
      "For epoch  13 loss is  [array(0.63833857, dtype=float32)]\n",
      "For epoch  14 loss is  [array(0.6346641, dtype=float32)]\n",
      "For epoch  15 loss is  [array(0.6310921, dtype=float32)]\n",
      "For epoch  16 loss is  [array(0.6276224, dtype=float32)]\n",
      "For epoch  17 loss is  [array(0.6242507, dtype=float32)]\n",
      "For epoch  18 loss is  [array(0.6209761, dtype=float32)]\n",
      "For epoch  19 loss is  [array(0.61779624, dtype=float32)]\n",
      "For epoch  20 loss is  [array(0.61471117, dtype=float32)]\n",
      "For epoch  21 loss is  [array(0.61171484, dtype=float32)]\n",
      "For epoch  22 loss is  [array(0.60880846, dtype=float32)]\n",
      "For epoch  23 loss is  [array(0.6059808, dtype=float32)]\n",
      "For epoch  24 loss is  [array(0.6032327, dtype=float32)]\n",
      "For epoch  25 loss is  [array(0.600554, dtype=float32)]\n",
      "For epoch  26 loss is  [array(0.59795547, dtype=float32)]\n",
      "For epoch  27 loss is  [array(0.59542847, dtype=float32)]\n",
      "For epoch  28 loss is  [array(0.59296733, dtype=float32)]\n",
      "For epoch  29 loss is  [array(0.5905699, dtype=float32)]\n",
      "For epoch  30 loss is  [array(0.58822656, dtype=float32)]\n",
      "For epoch  31 loss is  [array(0.58593655, dtype=float32)]\n",
      "For epoch  32 loss is  [array(0.58369577, dtype=float32)]\n",
      "For epoch  33 loss is  [array(0.58151007, dtype=float32)]\n",
      "For epoch  34 loss is  [array(0.57936966, dtype=float32)]\n",
      "For epoch  35 loss is  [array(0.57726705, dtype=float32)]\n",
      "For epoch  36 loss is  [array(0.5752052, dtype=float32)]\n",
      "For epoch  37 loss is  [array(0.57317626, dtype=float32)]\n",
      "For epoch  38 loss is  [array(0.57118034, dtype=float32)]\n",
      "For epoch  39 loss is  [array(0.569209, dtype=float32)]\n",
      "For epoch  40 loss is  [array(0.56726676, dtype=float32)]\n",
      "For epoch  41 loss is  [array(0.5653414, dtype=float32)]\n",
      "For epoch  42 loss is  [array(0.5634329, dtype=float32)]\n",
      "For epoch  43 loss is  [array(0.5615468, dtype=float32)]\n",
      "For epoch  44 loss is  [array(0.55966455, dtype=float32)]\n",
      "For epoch  45 loss is  [array(0.55779994, dtype=float32)]\n",
      "For epoch  46 loss is  [array(0.5559331, dtype=float32)]\n",
      "For epoch  47 loss is  [array(0.554079, dtype=float32)]\n",
      "For epoch  48 loss is  [array(0.55222684, dtype=float32)]\n",
      "For epoch  49 loss is  [array(0.55037886, dtype=float32)]\n",
      "For epoch  50 loss is  [array(0.5485286, dtype=float32)]\n",
      "For epoch  51 loss is  [array(0.54667395, dtype=float32)]\n",
      "For epoch  52 loss is  [array(0.5448135, dtype=float32)]\n",
      "For epoch  53 loss is  [array(0.54294556, dtype=float32)]\n",
      "For epoch  54 loss is  [array(0.5410782, dtype=float32)]\n",
      "For epoch  55 loss is  [array(0.5392004, dtype=float32)]\n",
      "For epoch  56 loss is  [array(0.53732014, dtype=float32)]\n",
      "For epoch  57 loss is  [array(0.5354297, dtype=float32)]\n",
      "For epoch  58 loss is  [array(0.5335361, dtype=float32)]\n",
      "For epoch  59 loss is  [array(0.5316368, dtype=float32)]\n",
      "For epoch  60 loss is  [array(0.52973604, dtype=float32)]\n",
      "For epoch  61 loss is  [array(0.5278289, dtype=float32)]\n",
      "For epoch  62 loss is  [array(0.52591765, dtype=float32)]\n",
      "For epoch  63 loss is  [array(0.5240014, dtype=float32)]\n",
      "For epoch  64 loss is  [array(0.52207494, dtype=float32)]\n",
      "For epoch  65 loss is  [array(0.52014184, dtype=float32)]\n",
      "For epoch  66 loss is  [array(0.5181978, dtype=float32)]\n",
      "For epoch  67 loss is  [array(0.5162431, dtype=float32)]\n",
      "For epoch  68 loss is  [array(0.51427823, dtype=float32)]\n",
      "For epoch  69 loss is  [array(0.51230127, dtype=float32)]\n",
      "For epoch  70 loss is  [array(0.51031303, dtype=float32)]\n",
      "For epoch  71 loss is  [array(0.50831074, dtype=float32)]\n",
      "For epoch  72 loss is  [array(0.50629854, dtype=float32)]\n",
      "For epoch  73 loss is  [array(0.5042742, dtype=float32)]\n",
      "For epoch  74 loss is  [array(0.5022363, dtype=float32)]\n",
      "For epoch  75 loss is  [array(0.5001851, dtype=float32)]\n",
      "For epoch  76 loss is  [array(0.4981251, dtype=float32)]\n",
      "For epoch  77 loss is  [array(0.49605176, dtype=float32)]\n",
      "For epoch  78 loss is  [array(0.49396846, dtype=float32)]\n",
      "For epoch  79 loss is  [array(0.49187472, dtype=float32)]\n",
      "For epoch  80 loss is  [array(0.48976696, dtype=float32)]\n",
      "For epoch  81 loss is  [array(0.48764932, dtype=float32)]\n",
      "For epoch  82 loss is  [array(0.48551333, dtype=float32)]\n",
      "For epoch  83 loss is  [array(0.483369, dtype=float32)]\n",
      "For epoch  84 loss is  [array(0.4812155, dtype=float32)]\n",
      "For epoch  85 loss is  [array(0.47905067, dtype=float32)]\n",
      "For epoch  86 loss is  [array(0.4768764, dtype=float32)]\n",
      "For epoch  87 loss is  [array(0.47469234, dtype=float32)]\n",
      "For epoch  88 loss is  [array(0.47250155, dtype=float32)]\n",
      "For epoch  89 loss is  [array(0.47030112, dtype=float32)]\n",
      "For epoch  90 loss is  [array(0.4680944, dtype=float32)]\n",
      "For epoch  91 loss is  [array(0.46587983, dtype=float32)]\n",
      "For epoch  92 loss is  [array(0.463659, dtype=float32)]\n",
      "For epoch  93 loss is  [array(0.4614268, dtype=float32)]\n",
      "For epoch  94 loss is  [array(0.45918822, dtype=float32)]\n",
      "For epoch  95 loss is  [array(0.45693982, dtype=float32)]\n",
      "For epoch  96 loss is  [array(0.45468423, dtype=float32)]\n",
      "For epoch  97 loss is  [array(0.4524183, dtype=float32)]\n",
      "For epoch  98 loss is  [array(0.45014447, dtype=float32)]\n",
      "For epoch  99 loss is  [array(0.44785395, dtype=float32)]\n",
      "For epoch  100 loss is  [array(0.44555384, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for e in range(num_epochs):\n",
    "    e_losses = train_epoch(model,optimizer ,criteria,x_train.shape[0])\n",
    "    print(\"For epoch \",e+1,\"loss is \",e_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numpy = test_data.values\n",
    "output1 = test_numpy[:,-1]\n",
    "output1=output1.astype('float64')\n",
    "#output1 = torch.Tensor(output1)\n",
    "test_sub = test_data.drop(['date','Occupancy'],axis=1)\n",
    "x_test = changeToTensor(test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test>0.5]=1\n",
    "test[test<=0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy is  78.98892534864643\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(test.shape[0]):\n",
    "    if(output1[i]==test[i]):\n",
    "        count = count+1\n",
    "print(\"Testing accuracy is \", (count/test.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a model with pytorch#####\n",
    "class Net_5(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(Net_5, self).__init__()\n",
    "        self.fc1 = nn.Linear(size,5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(5,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Net_5(x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_5(\n",
       "  (fc1): Linear(in_features=5, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss across epoch is  [0.43141136591027424, 0.351766392043451, 0.2974974678420439, 0.2551877216958418, 0.22293368236320774, 0.1987109073415035, 0.18033748765180752, 0.16614527302998594, 0.1548165412983153, 0.14553574649844228]  length of epoch is  10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "e_losses=[]\n",
    "loss_across_epoch=[]\n",
    "for e in range(num_epochs):\n",
    "    e_losses = train_epoch(model,optimizer ,criteria,100)\n",
    "    loss_to_plot = sum(e_losses)/len(e_losses)\n",
    "    loss_across_epoch.append(loss_to_plot)\n",
    "plt.plot(loss_across_epoch)\n",
    "print(\"Loss across epoch is \",loss_across_epoch,\" length of epoch is \",len(loss_across_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
